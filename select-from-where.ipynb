{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Select, From & Where**\n\n*Example: What are all the U.S. cities in the OpenAQ dataset?*\n\nWe'll work through an example with a real dataset. We'll use an OpenAQ dataset about air quality.\n\nFirst, we'll set up everything we need to run queries and take a quick peek at what tables are in our database. ","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"openaq\" dataset\ndataset_ref=client.dataset(\"openaq\",project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset=client.get_dataset(dataset_ref)\n\n# List all the tables in the \"openaq\" dataset\ntables = list(client.list_tables(dataset))\n\n# Print names of all tables in the dataset\nfor table in tables:  \n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:26:22.983808Z","iopub.execute_input":"2022-10-19T16:26:22.984270Z","iopub.status.idle":"2022-10-19T16:26:23.416176Z","shell.execute_reply.started":"2022-10-19T16:26:22.984217Z","shell.execute_reply":"2022-10-19T16:26:23.415301Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\nglobal_air_quality\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The dataset contains only one table, called global_air_quality. \n\nWe'll fetch the table and take a peek at the first few rows to see what sort of data it contains.\n","metadata":{}},{"cell_type":"code","source":"#construct a reference to the\"global_air_quality\" table\ntable_ref= dataset_ref.table(\"global_air_quality\")\n\n#api request\ntable=client.get_table(table_ref)\n\ntable.schema","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:26:27.279166Z","iopub.execute_input":"2022-10-19T16:26:27.279611Z","iopub.status.idle":"2022-10-19T16:26:27.556749Z","shell.execute_reply.started":"2022-10-19T16:26:27.279573Z","shell.execute_reply":"2022-10-19T16:26:27.555617Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[SchemaField('location', 'STRING', 'NULLABLE', None, (), None),\n SchemaField('city', 'STRING', 'NULLABLE', None, (), None),\n SchemaField('country', 'STRING', 'NULLABLE', None, (), None),\n SchemaField('pollutant', 'STRING', 'NULLABLE', None, (), None),\n SchemaField('value', 'FLOAT', 'NULLABLE', None, (), None),\n SchemaField('timestamp', 'TIMESTAMP', 'NULLABLE', None, (), None),\n SchemaField('unit', 'STRING', 'NULLABLE', None, (), None),\n SchemaField('source_name', 'STRING', 'NULLABLE', None, (), None),\n SchemaField('latitude', 'FLOAT', 'NULLABLE', None, (), None),\n SchemaField('longitude', 'FLOAT', 'NULLABLE', None, (), None),\n SchemaField('averaged_over_in_hours', 'FLOAT', 'NULLABLE', None, (), None),\n SchemaField('location_geom', 'GEOGRAPHY', 'NULLABLE', None, (), None)]"},"metadata":{}}]},{"cell_type":"code","source":"client.list_rows(table,max_results=6).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:27:47.245112Z","iopub.execute_input":"2022-10-19T16:27:47.245583Z","iopub.status.idle":"2022-10-19T16:27:47.791543Z","shell.execute_reply.started":"2022-10-19T16:27:47.245534Z","shell.execute_reply":"2022-10-19T16:27:47.790331Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                  location      city country pollutant    value  \\\n0   Borówiec, ul. Drapałka  Borówiec      PL        bc  0.85217   \n1    Kraków, ul. Bulwarowa    Kraków      PL        bc  0.91284   \n2          Płock, ul. Reja     Płock      PL        bc  1.41000   \n3  Elbląg, ul. Bażyńskiego    Elbląg      PL        bc  0.33607   \n4  Piastów, ul. Pułaskiego   Piastów      PL        bc  0.51000   \n5       Biała, ul. Kmicica     Biała      PL        bc  5.64000   \n\n                  timestamp   unit source_name  latitude  longitude  \\\n0 2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n1 2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n2 2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n3 2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n4 2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n5 2022-05-10 06:00:00+00:00  µg/m³        GIOS       1.0  52.602534   \n\n   averaged_over_in_hours       location_geom  \n0               17.074114  POINT(52.276794 1)  \n1               20.053492  POINT(50.069308 1)  \n2               19.709791  POINT(52.550938 1)  \n3               19.410942  POINT(54.167847 1)  \n4               20.837489  POINT(52.191728 1)  \n5               19.645100  POINT(52.602534 1)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>city</th>\n      <th>country</th>\n      <th>pollutant</th>\n      <th>value</th>\n      <th>timestamp</th>\n      <th>unit</th>\n      <th>source_name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>averaged_over_in_hours</th>\n      <th>location_geom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Borówiec, ul. Drapałka</td>\n      <td>Borówiec</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.85217</td>\n      <td>2022-04-28 07:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.276794</td>\n      <td>17.074114</td>\n      <td>POINT(52.276794 1)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kraków, ul. Bulwarowa</td>\n      <td>Kraków</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.91284</td>\n      <td>2022-04-27 23:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.069308</td>\n      <td>20.053492</td>\n      <td>POINT(50.069308 1)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Płock, ul. Reja</td>\n      <td>Płock</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>1.41000</td>\n      <td>2022-03-30 04:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.550938</td>\n      <td>19.709791</td>\n      <td>POINT(52.550938 1)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elbląg, ul. Bażyńskiego</td>\n      <td>Elbląg</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.33607</td>\n      <td>2022-05-03 13:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>54.167847</td>\n      <td>19.410942</td>\n      <td>POINT(54.167847 1)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Piastów, ul. Pułaskiego</td>\n      <td>Piastów</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.51000</td>\n      <td>2022-05-11 05:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.191728</td>\n      <td>20.837489</td>\n      <td>POINT(52.191728 1)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Biała, ul. Kmicica</td>\n      <td>Biała</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>5.64000</td>\n      <td>2022-05-10 06:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.602534</td>\n      <td>19.645100</td>\n      <td>POINT(52.602534 1)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Everything looks good! \nwe want to select all the values from the city column that are in rows where the country column is 'US' (for \"United States\").","metadata":{}},{"cell_type":"code","source":"# Query to select all the items from the \"city\" column where the \"country\" column is 'US'\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:31:38.216633Z","iopub.execute_input":"2022-10-19T16:31:38.217702Z","iopub.status.idle":"2022-10-19T16:31:38.222561Z","shell.execute_reply.started":"2022-10-19T16:31:38.217657Z","shell.execute_reply":"2022-10-19T16:31:38.221341Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Submitting the query to the dataset**\n\nUse the query to get information from the OpenAQ dataset.The first step is to create a Client object.","metadata":{}},{"cell_type":"code","source":"# Create a \"Client\" object\nclient=bigquery.Client()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:35:17.951026Z","iopub.execute_input":"2022-10-19T16:35:17.951460Z","iopub.status.idle":"2022-10-19T16:35:17.958279Z","shell.execute_reply.started":"2022-10-19T16:35:17.951426Z","shell.execute_reply":"2022-10-19T16:35:17.957015Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We begin by setting up the query with the query() method. We run the method with the default parameters, but this method also allows us to specify more complicated settings.","metadata":{}},{"cell_type":"code","source":"#setup the query\nquery_job = client.query(query)\n\n# API request - run the query and return a pandas DataFrame\nus_cities=query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:38:26.491055Z","iopub.execute_input":"2022-10-19T16:38:26.491468Z","iopub.status.idle":"2022-10-19T16:38:52.121171Z","shell.execute_reply.started":"2022-10-19T16:38:26.491435Z","shell.execute_reply":"2022-10-19T16:38:52.119839Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now we've got a pandas DataFrame called us_cities, which we can use like any other DataFrame.","metadata":{}},{"cell_type":"code","source":"#what five cities have the most measurments ?\nus_cities.city.value_counts().head()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:41:53.947881Z","iopub.execute_input":"2022-10-19T16:41:53.948397Z","iopub.status.idle":"2022-10-19T16:41:54.022697Z","shell.execute_reply.started":"2022-10-19T16:41:53.948355Z","shell.execute_reply":"2022-10-19T16:41:54.021354Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Phoenix-Mesa-Scottsdale                     39414\nLos Angeles-Long Beach-Santa Ana            27479\nRiverside-San Bernardino-Ontario            26887\nNew York-Northern New Jersey-Long Island    25417\nSan Francisco-Oakland-Fremont               22710\nName: city, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**More queries**\n","metadata":{}},{"cell_type":"code","source":"query=\"\"\"\nSELECT city,country\nFROM `bigquery-public-data.openaq.global_air_quality`\nWHERE country= 'US'\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query = \"\"\"\n        SELECT *\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Working with big datasets**\n\nwe can estimate the size of any query before running it. Here is an example using the (very large!) Hacker News dataset. To see how much data a query will scan, we create a QueryJobConfig object and set the dry_run parameter to True","metadata":{}},{"cell_type":"code","source":"# Query to get the score column from every row where the type column has value \"job\"\nquery = \"\"\"\n        SELECT score, title\n        FROM `bigquery-public-data.hacker_news.full`\n        WHERE type = \"job\" \n        \"\"\"\n\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job = client.query(query, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:47:32.450285Z","iopub.execute_input":"2022-10-19T16:47:32.450718Z","iopub.status.idle":"2022-10-19T16:47:32.877448Z","shell.execute_reply.started":"2022-10-19T16:47:32.450684Z","shell.execute_reply":"2022-10-19T16:47:32.876066Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"This query will process 548427502 bytes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":" we can specify a parameter when running the query to limit how much data we are willing to scan. Here's an example with a low limit.","metadata":{}},{"cell_type":"code","source":"# Only run the query if it's less than 1 MB\nONE_MB = 1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n\n# Set up the query (will only run if it's less than 1 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\nsafe_query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:49:10.288904Z","iopub.execute_input":"2022-10-19T16:49:10.289430Z","iopub.status.idle":"2022-10-19T16:49:10.761312Z","shell.execute_reply.started":"2022-10-19T16:49:10.289389Z","shell.execute_reply":"2022-10-19T16:49:10.759765Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2063017411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# API request - try to run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msafe_query_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, date_as_object)\u001b[0m\n\u001b[1;32m   3403\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \"\"\"\n\u001b[0;32m-> 3405\u001b[0;31m         return self.result().to_dataframe(\n\u001b[0m\u001b[1;32m   3406\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m             \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index)\u001b[0m\n\u001b[1;32m   3232\u001b[0m         \"\"\"\n\u001b[1;32m   3233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3234\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3236\u001b[0m             \u001b[0;31m# Return an iterator instead of returning the job.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalServerError\u001b[0m: 500 Query exceeded limit for bytes billed: 1000000. 549453824 or higher required.\n\n(job ID: a01d5e30-2010-493c-baf7-7f2bc6905b01)\n\n             -----Query Job SQL Follows-----             \n\n    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:        SELECT score, title\n   3:        FROM `bigquery-public-data.hacker_news.full`\n   4:        WHERE type = \"job\" \n   5:        \n    |    .    |    .    |    .    |    .    |    .    |"],"ename":"InternalServerError","evalue":"500 Query exceeded limit for bytes billed: 1000000. 549453824 or higher required.\n\n(job ID: a01d5e30-2010-493c-baf7-7f2bc6905b01)\n\n             -----Query Job SQL Follows-----             \n\n    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:        SELECT score, title\n   3:        FROM `bigquery-public-data.hacker_news.full`\n   4:        WHERE type = \"job\" \n   5:        \n    |    .    |    .    |    .    |    .    |    .    |","output_type":"error"}]},{"cell_type":"markdown","source":"In this case, the query was cancelled, because the limit of 1 MB was exceeded. However, we can increase the limit to run the query successfully!","metadata":{}},{"cell_type":"code","source":"# Only run the query if it's less than 1 GB\nONE_GB = 1000*1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n\n# Set up the query (will only run if it's less than 1 GB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\njob_post_scores = safe_query_job.to_dataframe()\n\n# Print average score for job posts\njob_post_scores.score.mean()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:49:53.049456Z","iopub.execute_input":"2022-10-19T16:49:53.049879Z","iopub.status.idle":"2022-10-19T16:49:55.866334Z","shell.execute_reply.started":"2022-10-19T16:49:53.049847Z","shell.execute_reply":"2022-10-19T16:49:55.865016Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1.7298668775537103"},"metadata":{}}]}]}